# Hybrid-NeuroSLAM: A neurobiologically inspired hybrid Visual-Inertial SLAM method for Large Scale Environment
Tengfei Lu, Zhongli Wang, Xiaoyang Fan, Yan Shen, Xiaotao Shao

<!-- #### [Project Page](https://16lemoing.github.io/dot) | [Paper](https://arxiv.org/abs/2312.00786) | [Video](https://www.youtube.com/watch?v=H0Rvq0OL87Y) | [BibTeX](#citation) -->

<!-- <p align="center"><img width="85%" src="assets/teaser.gif" /></p> -->


Animals in nature exhibit remarkable spatial cognition abilities, enabling them to achieve long-distance autonomous navigation efficiently in unknown environments. Neurobiologically inspired SLAM methods primarily aim to mimic this capability of spatial cognition and navigation. However, existing works have only been able to perform rough velocity estimation with scanline intensity profiles, which may lead to a severely distorted cognitive map, particularly in large scale environment. This work presents a novel neurobiologically inspired Visual-Inertial SLAM method, called Hybrid-NueroSLAM, that addresses two issues: precisely visual-inertial fusion-based motion estimate and map consistency for large size environment. 
Based on high-precision Visual-Inertial odometry, a precise and robust visual memory mechanism, and a neural cell network based on our proposed Improved Bayesian Attractor for spatial cognition, it constructs a semi-metric topological experience map.




- **Running on:** AMD R7 5800H with 16G RAM DDR4 3200MHz



> We will open source the source code of this work after the paper is accepted.